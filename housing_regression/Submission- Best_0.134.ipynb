{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps to follow when working with real world data\n",
    "#1. Load data\n",
    "#2. Look at data to remove irrelevant data\n",
    "#3. Finding missing values \n",
    "#4. Understand categories\n",
    "#5. Pick a model\n",
    "\n",
    "# Lets look at a real world problem such as home price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install catboost\n",
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('train.csv')\n",
    "df2 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select output target\n",
    "y = df.SalePrice\n",
    "x = df.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================DATA HANDLING ============================##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 80)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#num_col = x.loc[:,'MSSubClass':'SaleCondition'].select_dtypes(exclude=['object']).columns\n",
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.7 * IQR ## increased to 1.7\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers \n",
    "Outliers_to_drop = detect_outliers(x,2, x.select_dtypes(exclude=['object']))\n",
    "x.loc[Outliers_to_drop] # Show the outliers rows\n",
    "x = x.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
    "y = y.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356,)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing value</th>\n",
       "      <th>N unique value</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0</td>\n",
       "      <td>1356</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>230</td>\n",
       "      <td>107</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0</td>\n",
       "      <td>997</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Missing value  N unique value    dtype\n",
       "Id                         0            1356    int64\n",
       "MSSubClass                 0              15    int64\n",
       "MSZoning                   0               5   object\n",
       "LotFrontage              230             107  float64\n",
       "LotArea                    0             997    int64\n",
       "...                      ...             ...      ...\n",
       "MiscVal                    0              16    int64\n",
       "MoSold                     0              12    int64\n",
       "YrSold                     0               5    int64\n",
       "SaleType                   0               9   object\n",
       "SaleCondition              0               6   object\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before tuning\n",
    "def basic_details(df):\n",
    "    b = pd.DataFrame()\n",
    "    b['Missing value'] = df.isnull().sum()\n",
    "    b['N unique value'] = df.nunique()\n",
    "    b['dtype'] = df.dtypes\n",
    "    return b\n",
    "basic_details(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df = x\n",
    "\n",
    "df['MSZoning'].fillna('N')\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].median(), inplace = True)\n",
    "df['Alley'].fillna('N',inplace=True)\n",
    "df['Exterior1st'].fillna('N')\n",
    "df['Exterior2nd'].fillna('N')\n",
    "df['Utilities'].fillna('N')\n",
    "df['MasVnrType'].fillna('N',inplace=True)\n",
    "df['BsmtFullBath'].fillna(0)\n",
    "df['BsmtHalfBath'].fillna(0)\n",
    "df['FullBath'].fillna(0)\n",
    "df['HalfBath'].fillna(0)\n",
    "df['KitchenQual'].fillna('N')\n",
    "df['Functional'].fillna('N')\n",
    "df['FireplaceQu'].fillna('N',inplace=True)\n",
    "df['GarageType'].fillna('N',inplace=True)\n",
    "df['GarageYrBlt'].fillna(0,inplace=True)\n",
    "df['GarageFinish'].fillna('N',inplace=True)\n",
    "df['GarageCars'].fillna(0)\n",
    "df['GarageArea'].fillna(0,inplace=True)\n",
    "df['GarageQual'].fillna('N',inplace=True)\n",
    "df['GarageCond'].fillna('N',inplace=True)\n",
    "df['BsmtFinSF2'].fillna(0,inplace=True)\n",
    "df['MasVnrArea'].fillna(0,inplace=True)\n",
    "df['BsmtFinSF1'].fillna(0,inplace=True)\n",
    "df['SaleType'].fillna('N')\n",
    "df['BsmtUnfSF'].fillna(0,inplace=True)\n",
    "df['TotalBsmtSF'].fillna(0,inplace=True)\n",
    "df['PoolQC'].fillna('N',inplace=True)\n",
    "df['Fence'].fillna('N',inplace=True)\n",
    "df['MiscFeature'].fillna('N',inplace=True)\n",
    "df['BsmtQual'].fillna('N',inplace=True)\n",
    "df['BsmtCond'].fillna('N',inplace=True)\n",
    "df['BsmtExposure'].fillna('N',inplace=True)\n",
    "df['BsmtFinType1'].fillna('N',inplace=True)\n",
    "df['BsmtFinType2'].fillna('N',inplace=True)\n",
    "df['Electrical'].fillna('N',inplace=True)\n",
    "df[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n",
    "df['Area'] = df['LotArea']*df['LotFrontage']\n",
    "df['Area_log'] = np.log1p(df['Area'])\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (df.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
    "x= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df = df2\n",
    "df['MSZoning'].fillna('N',inplace=True)\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].median(), inplace = True)\n",
    "df['Alley'].fillna('N',inplace=True)\n",
    "df['Exterior1st'].fillna('N',inplace=True)\n",
    "df['Exterior2nd'].fillna('N',inplace=True)\n",
    "df['Utilities'].fillna('N',inplace=True)\n",
    "df['MasVnrType'].fillna('N',inplace=True)\n",
    "df['BsmtFullBath'].fillna(0,inplace=True)\n",
    "df['BsmtHalfBath'].fillna(0,inplace=True)\n",
    "df['FullBath'].fillna(0)\n",
    "df['HalfBath'].fillna(0)\n",
    "df['KitchenQual'].fillna('N',inplace=True)\n",
    "df['Functional'].fillna('N',inplace=True)\n",
    "df['FireplaceQu'].fillna('N',inplace=True)\n",
    "df['GarageType'].fillna('N',inplace=True)\n",
    "df['GarageYrBlt'].fillna(0,inplace=True)\n",
    "df['GarageFinish'].fillna('N',inplace=True)\n",
    "df['GarageCars'].fillna(0,inplace=True)\n",
    "df['GarageArea'].fillna(0,inplace=True)\n",
    "df['GarageQual'].fillna('N',inplace=True)\n",
    "df['GarageCond'].fillna('N',inplace=True)\n",
    "df['BsmtFinSF2'].fillna(0,inplace=True)\n",
    "df['MasVnrArea'].fillna(0,inplace=True)\n",
    "df['BsmtFinSF1'].fillna(0,inplace=True)\n",
    "df['SaleType'].fillna('N',inplace=True)\n",
    "df['BsmtUnfSF'].fillna(0,inplace=True)\n",
    "df['TotalBsmtSF'].fillna(0,inplace=True)\n",
    "df['PoolQC'].fillna('N',inplace=True)\n",
    "df['Fence'].fillna('N',inplace=True)\n",
    "df['MiscFeature'].fillna('N',inplace=True)\n",
    "df['BsmtQual'].fillna('N',inplace=True)\n",
    "df['BsmtCond'].fillna('N',inplace=True)\n",
    "df['BsmtExposure'].fillna('N',inplace=True)\n",
    "df['BsmtFinType1'].fillna('N',inplace=True)\n",
    "df['BsmtFinType2'].fillna('N',inplace=True)\n",
    "df['Electrical'].fillna('N',inplace=True)\n",
    "df[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n",
    "df['Area'] = df['LotArea']*df['LotFrontage']\n",
    "df['Area_log'] = np.log1p(df['Area'])\n",
    "\n",
    "x2=df2\n",
    "missing_val_count_by_column = (x2.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 83)\n",
      "(1356, 151)\n",
      "(1459, 83)\n",
      "(1459, 151)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
      "/var/folders/6l/f406sbm938jcwm7939s8dl900000gn/T/ipykernel_6637/1814147513.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n"
     ]
    }
   ],
   "source": [
    "def descrictive_stat_feat(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol= [c for c in df.columns if df[c].nunique()>=10]\n",
    "    d_median = df[dcol].median(axis=0)\n",
    "    d_mean = df[dcol].mean(axis=0)\n",
    "    q1 = df[dcol].apply(np.int64).quantile(0.25)\n",
    "    q3 = df[dcol].apply(np.int64).quantile(0.75)\n",
    "    \n",
    "    #Add mean and median column to data set having more then 10 categories\n",
    "    for c in dcol:\n",
    "        df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n",
    "        df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n",
    "        df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n",
    "        df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n",
    "    return df\n",
    "\n",
    "df = x\n",
    "print(df.shape)\n",
    "numericCols = (df.iloc[:, (np.where((df.dtypes == np.int64) | (df.dtypes == np.float64)))[0]].columns)\n",
    "numericCols = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
    "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
    "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
    "       'MiscVal', 'MoSold', 'YrSold', 'AllSF', 'Area', 'Area_log']\n",
    "\n",
    "x = descrictive_stat_feat(df[numericCols])\n",
    "#print(newCols)\n",
    "#df = df.assign(newCols)\n",
    "print(x.shape)\n",
    "\n",
    "df = x2\n",
    "print(df.shape)\n",
    "numericCols = (df.iloc[:, (np.where((df.dtypes == np.int64) | (df.dtypes == np.float64)))[0]].columns)\n",
    "numericCols = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
    "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
    "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
    "       'MiscVal', 'MoSold', 'YrSold', 'AllSF', 'Area', 'Area_log']\n",
    "x2 = descrictive_stat_feat(df[numericCols])\n",
    "print(x2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 83)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "cols_with_missing\n",
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer( strategy='constant', fill_value=\"None\")\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "X_train = imputed_X_train_plus\n",
    "X_valid = imputed_X_valid_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling categorial values with ordinal and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'MiscFeature', 'RoofStyle', 'Heating', 'Condition2', 'RoofMatl']\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "oe_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "oe_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "oe_x2_test = x2.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "oe_X_train[good_label_cols] = ordinal_encoder.fit_transform(oe_X_train[good_label_cols])\n",
    "oe_X_valid[good_label_cols] = ordinal_encoder.transform(oe_X_valid[good_label_cols])\n",
    "oe_x2_test[good_label_cols] = ordinal_encoder.fit_transform(oe_x2_test[good_label_cols])\n",
    "# Categorical columns in the test data\n",
    "#object_cols = [col for col in oe_x2_test.columns if oe_x2_test[col].dtype == \"object\"]\n",
    "#oe_x2_test[object_cols] = ordinal_encoder.fit_transform(oe_x2_test[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 77)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 77)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe_x2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##One - hot encoding\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])\n",
    "\n",
    "## Identifying cardinality\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 20 and \n",
    "                        X_train[cname].dtype == \"object\"]\n",
    "low_cardinality_cols\n",
    "\n",
    "\n",
    "\n",
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 20]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "#print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "#print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(x2[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "OH_cols_test.index = x2.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "num_X_test = x2.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 CatBoost\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def cbf(X_train, X_valid, y_train, y_valid, test):\n",
    "    model = cb.CatBoostRegressor(loss_function='RMSE', silent=True)\n",
    "    \n",
    "    \n",
    "    params = {'iterations': [500],\n",
    "          'depth': [4, 5, 6],\n",
    "          'l2_leaf_reg': np.logspace(-20, -19, 3),\n",
    "          'leaf_estimation_iterations': [10],\n",
    "#           'eval_metric': ['Accuracy'],\n",
    "#           'use_best_model': ['True'],\n",
    "          'random_seed': [42]\n",
    "         }\n",
    "    \n",
    "   # Grid_CBC = GridSearchCV(estimator=model, param_grid = params, cv = 2, n_jobs=-1)\n",
    "  #  Grid_CBC.fit(X_train, y_train)\n",
    "    \n",
    " #    print(\"\\n The best estimator across ALL searched params:\\n\",Grid_CBC.best_estimator_)\n",
    "#    print(\"\\n The best score across ALL searched params:\\n\",Grid_CBC.best_score_)\n",
    "#    print(\"\\n The best parameters across ALL searched params:\\n\",Grid_CBC.best_params_)\n",
    "    \n",
    "    model = cb.CatBoostRegressor(loss_function='RMSE', silent=True,\n",
    "                                iterations=500,\n",
    "                           depth=4,\n",
    "                           l2_leaf_reg=1e-20,\n",
    "                           eval_metric='Accuracy',\n",
    "                           leaf_estimation_iterations=10,\n",
    "                           random_seed=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "\n",
    "    test_preds = model.predict(test)\n",
    "\n",
    "\n",
    "    return (mean_absolute_error(y_valid, preds), r2_score(y_valid,preds), test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "def xg(x_train, x_valid, y_train, y_valid, test):\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    params = {\n",
    "        'objective':'reg:linear',\n",
    "#         'n_estimators': 50,\n",
    "        'booster':'gbtree',\n",
    "        'max_depth':2,\n",
    "        'eval_metric':'rmse',\n",
    "        'learning_rate':0.1, \n",
    "        'min_child_weight':1,\n",
    "        'subsample':0.80,\n",
    "        'colsample_bytree':0.81,\n",
    "        'seed':45,\n",
    "        'reg_alpha':1,#1e-03,\n",
    "        'reg_lambda':0,\n",
    "        'gamma':0,\n",
    "        'nthread':-1\n",
    "\n",
    "    }\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    clf = xgb.train(params, d_train, 2000,  watchlist, early_stopping_rounds=300, maximize=False, verbose_eval=10)\n",
    "    preds = clf.predict(d_valid)\n",
    "    test_preds = clf.predict(d_test)\n",
    "    return (mean_absolute_error(y_valid, preds), r2_score(y_valid,preds), test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (OE):\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/private/libs/target/target_converter.cpp:379: Target with classes must contain only 2 unique values for binary classification",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [399]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE from Approach 1 (OE):\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 2\u001b[0m a,b, oe \u001b[38;5;241m=\u001b[39m \u001b[43mcbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moe_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moe_X_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moe_x2_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(a,b,oe)\n",
      "Input \u001b[0;32mIn [398]\u001b[0m, in \u001b[0;36mcbf\u001b[0;34m(X_train, X_valid, y_train, y_valid, test)\u001b[0m\n\u001b[1;32m     21\u001b[0m    \u001b[38;5;66;03m# Grid_CBC = GridSearchCV(estimator=model, param_grid = params, cv = 2, n_jobs=-1)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m#  Grid_CBC.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \n\u001b[1;32m     24\u001b[0m  \u001b[38;5;66;03m#    print(\"\\n The best estimator across ALL searched params:\\n\",Grid_CBC.best_estimator_)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#    print(\"\\n The best score across ALL searched params:\\n\",Grid_CBC.best_score_)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#    print(\"\\n The best parameters across ALL searched params:\\n\",Grid_CBC.best_params_)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     model \u001b[38;5;241m=\u001b[39m cb\u001b[38;5;241m.\u001b[39mCatBoostRegressor(loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m                                 iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     30\u001b[0m                            depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m                            leaf_estimation_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     34\u001b[0m                            random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n\u001b[1;32m     39\u001b[0m     test_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/catboost/core.py:5590\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5588\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5591\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5592\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5593\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/catboost/core.py:2278\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2274\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2277\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/catboost/core.py:1705\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4585\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4634\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/private/libs/target/target_converter.cpp:379: Target with classes must contain only 2 unique values for binary classification"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (OE):\") \n",
    "a,b, oe = cbf(oe_X_train, oe_X_valid, y_train, y_valid, oe_x2_test)\n",
    "print(a,b,oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.base.Index'>\n",
      "[]\n",
      "MAE from Approach 1 (OH):\n",
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " <catboost.core.CatBoostRegressor object at 0x284269220>\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8990520580428699\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'depth': 4, 'iterations': 500, 'l2_leaf_reg': 1e-20, 'leaf_estimation_iterations': 10, 'random_seed': 42}\n",
      "13656.178898672426 0.9280996016805295 [127779.43740156 164239.04434433 187817.00157925 ... 178184.84615299\n",
      " 117657.39765796 233055.4372881 ]\n"
     ]
    }
   ],
   "source": [
    "#Deleting uncommon columns\n",
    "a = OH_X_train.columns.intersection(OH_X_test.columns) \n",
    "print(type(OH_X_test.columns))\n",
    "\n",
    "c = [ element for element in OH_X_train.columns if element not in OH_X_test.columns] \n",
    "d = [ element for element in OH_X_test.columns if element not in OH_X_train.columns] \n",
    "print(c)\n",
    "OH_X_test = OH_X_test.reindex(columns=OH_X_train.columns)\n",
    "\n",
    "print(\"MAE from Approach 1 (OH):\") \n",
    "a,b, OH = cbf(OH_X_train, OH_X_valid, y_train, y_valid, OH_X_test)\n",
    "print(a,b,OH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (OE):\n",
      "[20:14:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\ttrain-rmse:172248.92719\tvalid-rmse:180236.17487\n",
      "[10]\ttrain-rmse:67299.78653\tvalid-rmse:72052.10328\n",
      "[20]\ttrain-rmse:34121.78279\tvalid-rmse:38317.44767\n",
      "[30]\ttrain-rmse:24486.95169\tvalid-rmse:29432.92648\n",
      "[40]\ttrain-rmse:21290.14306\tvalid-rmse:26772.89963\n",
      "[50]\ttrain-rmse:19657.25702\tvalid-rmse:25858.11881\n",
      "[60]\ttrain-rmse:18564.76885\tvalid-rmse:25232.49609\n",
      "[70]\ttrain-rmse:17705.37334\tvalid-rmse:24717.77149\n",
      "[80]\ttrain-rmse:17084.35546\tvalid-rmse:24444.88362\n",
      "[90]\ttrain-rmse:16572.50259\tvalid-rmse:24141.12435\n",
      "[100]\ttrain-rmse:16047.75333\tvalid-rmse:23777.37514\n",
      "[110]\ttrain-rmse:15619.82576\tvalid-rmse:23676.70320\n",
      "[120]\ttrain-rmse:15138.33283\tvalid-rmse:23429.04089\n",
      "[130]\ttrain-rmse:14801.22122\tvalid-rmse:23435.74399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisheksinghal/miniforge3/lib/python3.9/site-packages/xgboost/core.py:525: FutureWarning: Pass `evals` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140]\ttrain-rmse:14440.84537\tvalid-rmse:23235.20309\n",
      "[150]\ttrain-rmse:14139.71990\tvalid-rmse:23089.31826\n",
      "[160]\ttrain-rmse:13904.64635\tvalid-rmse:23009.35740\n",
      "[170]\ttrain-rmse:13674.93463\tvalid-rmse:22902.63028\n",
      "[180]\ttrain-rmse:13440.65882\tvalid-rmse:22798.05267\n",
      "[190]\ttrain-rmse:13229.27021\tvalid-rmse:22868.35105\n",
      "[200]\ttrain-rmse:13004.53606\tvalid-rmse:22789.18748\n",
      "[210]\ttrain-rmse:12815.40017\tvalid-rmse:22798.48955\n",
      "[220]\ttrain-rmse:12623.56237\tvalid-rmse:22797.75444\n",
      "[230]\ttrain-rmse:12418.67460\tvalid-rmse:22690.13044\n",
      "[240]\ttrain-rmse:12231.43755\tvalid-rmse:22630.57117\n",
      "[250]\ttrain-rmse:12018.91891\tvalid-rmse:22588.66131\n",
      "[260]\ttrain-rmse:11858.89556\tvalid-rmse:22542.14932\n",
      "[270]\ttrain-rmse:11735.77633\tvalid-rmse:22552.80823\n",
      "[280]\ttrain-rmse:11576.36169\tvalid-rmse:22484.62621\n",
      "[290]\ttrain-rmse:11407.59172\tvalid-rmse:22470.51602\n",
      "[300]\ttrain-rmse:11272.17972\tvalid-rmse:22427.42714\n",
      "[310]\ttrain-rmse:11122.26951\tvalid-rmse:22444.05566\n",
      "[320]\ttrain-rmse:10966.50057\tvalid-rmse:22388.66245\n",
      "[330]\ttrain-rmse:10829.99247\tvalid-rmse:22328.64276\n",
      "[340]\ttrain-rmse:10652.49050\tvalid-rmse:22233.13277\n",
      "[350]\ttrain-rmse:10540.53209\tvalid-rmse:22146.84730\n",
      "[360]\ttrain-rmse:10411.86787\tvalid-rmse:22152.29027\n",
      "[370]\ttrain-rmse:10298.96091\tvalid-rmse:22085.01740\n",
      "[380]\ttrain-rmse:10192.35772\tvalid-rmse:22058.61338\n",
      "[390]\ttrain-rmse:10056.45964\tvalid-rmse:22038.95049\n",
      "[400]\ttrain-rmse:9902.65230\tvalid-rmse:22042.20818\n",
      "[410]\ttrain-rmse:9800.87507\tvalid-rmse:22022.20549\n",
      "[420]\ttrain-rmse:9696.50287\tvalid-rmse:21968.42066\n",
      "[430]\ttrain-rmse:9592.99331\tvalid-rmse:21976.18389\n",
      "[440]\ttrain-rmse:9519.90869\tvalid-rmse:21918.45956\n",
      "[450]\ttrain-rmse:9430.15942\tvalid-rmse:21905.93424\n",
      "[460]\ttrain-rmse:9347.38627\tvalid-rmse:21917.87328\n",
      "[470]\ttrain-rmse:9258.30840\tvalid-rmse:21903.80165\n",
      "[480]\ttrain-rmse:9153.42820\tvalid-rmse:21833.35137\n",
      "[490]\ttrain-rmse:9070.08092\tvalid-rmse:21849.45562\n",
      "[500]\ttrain-rmse:8985.21510\tvalid-rmse:21884.57220\n",
      "[510]\ttrain-rmse:8869.40784\tvalid-rmse:21865.28470\n",
      "[520]\ttrain-rmse:8785.19645\tvalid-rmse:21842.91239\n",
      "[530]\ttrain-rmse:8688.36847\tvalid-rmse:21850.04770\n",
      "[540]\ttrain-rmse:8597.45970\tvalid-rmse:21890.54870\n",
      "[550]\ttrain-rmse:8518.71335\tvalid-rmse:21910.34994\n",
      "[560]\ttrain-rmse:8446.83398\tvalid-rmse:21870.05226\n",
      "[570]\ttrain-rmse:8371.07001\tvalid-rmse:21881.55284\n",
      "[580]\ttrain-rmse:8291.02000\tvalid-rmse:21878.31154\n",
      "[590]\ttrain-rmse:8216.44759\tvalid-rmse:21843.71817\n",
      "[600]\ttrain-rmse:8135.55259\tvalid-rmse:21839.51420\n",
      "[610]\ttrain-rmse:8065.16428\tvalid-rmse:21807.94263\n",
      "[620]\ttrain-rmse:8013.23886\tvalid-rmse:21824.31122\n",
      "[630]\ttrain-rmse:7949.95816\tvalid-rmse:21814.17185\n",
      "[640]\ttrain-rmse:7897.24683\tvalid-rmse:21835.91991\n",
      "[650]\ttrain-rmse:7829.08889\tvalid-rmse:21833.81868\n",
      "[660]\ttrain-rmse:7761.17445\tvalid-rmse:21835.89071\n",
      "[670]\ttrain-rmse:7708.29458\tvalid-rmse:21824.19447\n",
      "[680]\ttrain-rmse:7632.42985\tvalid-rmse:21810.21079\n",
      "[690]\ttrain-rmse:7564.34971\tvalid-rmse:21769.72035\n",
      "[700]\ttrain-rmse:7508.93791\tvalid-rmse:21785.94293\n",
      "[710]\ttrain-rmse:7453.42868\tvalid-rmse:21768.33028\n",
      "[720]\ttrain-rmse:7397.88616\tvalid-rmse:21718.64887\n",
      "[730]\ttrain-rmse:7334.63487\tvalid-rmse:21707.69208\n",
      "[740]\ttrain-rmse:7260.25015\tvalid-rmse:21708.19604\n",
      "[750]\ttrain-rmse:7214.81179\tvalid-rmse:21706.33671\n",
      "[760]\ttrain-rmse:7155.41107\tvalid-rmse:21690.83677\n",
      "[770]\ttrain-rmse:7072.17489\tvalid-rmse:21678.75087\n",
      "[780]\ttrain-rmse:7010.16847\tvalid-rmse:21685.42856\n",
      "[790]\ttrain-rmse:6942.96909\tvalid-rmse:21697.66641\n",
      "[800]\ttrain-rmse:6883.29683\tvalid-rmse:21688.59647\n",
      "[810]\ttrain-rmse:6835.04431\tvalid-rmse:21691.11765\n",
      "[820]\ttrain-rmse:6780.58445\tvalid-rmse:21655.08228\n",
      "[830]\ttrain-rmse:6728.71135\tvalid-rmse:21623.22172\n",
      "[840]\ttrain-rmse:6672.58607\tvalid-rmse:21603.54173\n",
      "[850]\ttrain-rmse:6624.95147\tvalid-rmse:21607.61576\n",
      "[860]\ttrain-rmse:6576.81207\tvalid-rmse:21597.37567\n",
      "[870]\ttrain-rmse:6510.68949\tvalid-rmse:21598.16158\n",
      "[880]\ttrain-rmse:6447.35993\tvalid-rmse:21559.10156\n",
      "[890]\ttrain-rmse:6399.31357\tvalid-rmse:21570.19015\n",
      "[900]\ttrain-rmse:6332.29691\tvalid-rmse:21588.17621\n",
      "[910]\ttrain-rmse:6291.96145\tvalid-rmse:21602.31681\n",
      "[920]\ttrain-rmse:6249.00329\tvalid-rmse:21609.69494\n",
      "[930]\ttrain-rmse:6202.07533\tvalid-rmse:21596.11883\n",
      "[940]\ttrain-rmse:6154.68102\tvalid-rmse:21590.80327\n",
      "[950]\ttrain-rmse:6102.97238\tvalid-rmse:21570.81680\n",
      "[960]\ttrain-rmse:6061.89131\tvalid-rmse:21548.38212\n",
      "[970]\ttrain-rmse:6014.53500\tvalid-rmse:21519.46103\n",
      "[980]\ttrain-rmse:5958.44810\tvalid-rmse:21517.11481\n",
      "[990]\ttrain-rmse:5916.46262\tvalid-rmse:21522.86532\n",
      "[1000]\ttrain-rmse:5867.08994\tvalid-rmse:21525.88797\n",
      "[1010]\ttrain-rmse:5820.80942\tvalid-rmse:21529.10419\n",
      "[1020]\ttrain-rmse:5774.61478\tvalid-rmse:21531.85281\n",
      "[1030]\ttrain-rmse:5723.86280\tvalid-rmse:21538.06641\n",
      "[1040]\ttrain-rmse:5686.52976\tvalid-rmse:21531.65241\n",
      "[1050]\ttrain-rmse:5635.91285\tvalid-rmse:21495.26021\n",
      "[1060]\ttrain-rmse:5592.96037\tvalid-rmse:21485.18349\n",
      "[1070]\ttrain-rmse:5548.87546\tvalid-rmse:21486.20199\n",
      "[1080]\ttrain-rmse:5512.35437\tvalid-rmse:21481.07353\n",
      "[1090]\ttrain-rmse:5471.12437\tvalid-rmse:21484.75639\n",
      "[1100]\ttrain-rmse:5421.69260\tvalid-rmse:21475.98064\n",
      "[1110]\ttrain-rmse:5377.24090\tvalid-rmse:21467.75428\n",
      "[1120]\ttrain-rmse:5337.80881\tvalid-rmse:21456.89758\n",
      "[1130]\ttrain-rmse:5301.94340\tvalid-rmse:21456.67371\n",
      "[1140]\ttrain-rmse:5264.98798\tvalid-rmse:21446.73958\n",
      "[1150]\ttrain-rmse:5233.04452\tvalid-rmse:21439.89884\n",
      "[1160]\ttrain-rmse:5192.57375\tvalid-rmse:21421.81290\n",
      "[1170]\ttrain-rmse:5150.14102\tvalid-rmse:21416.97289\n",
      "[1180]\ttrain-rmse:5118.97585\tvalid-rmse:21427.48901\n",
      "[1190]\ttrain-rmse:5074.10360\tvalid-rmse:21412.70048\n",
      "[1200]\ttrain-rmse:5031.12380\tvalid-rmse:21439.39837\n",
      "[1210]\ttrain-rmse:4994.41417\tvalid-rmse:21432.31162\n",
      "[1220]\ttrain-rmse:4950.73202\tvalid-rmse:21443.24751\n",
      "[1230]\ttrain-rmse:4918.31444\tvalid-rmse:21431.17152\n",
      "[1240]\ttrain-rmse:4881.78943\tvalid-rmse:21423.75888\n",
      "[1250]\ttrain-rmse:4852.22397\tvalid-rmse:21397.07469\n",
      "[1260]\ttrain-rmse:4822.02276\tvalid-rmse:21419.69945\n",
      "[1270]\ttrain-rmse:4774.86451\tvalid-rmse:21396.64261\n",
      "[1280]\ttrain-rmse:4738.00951\tvalid-rmse:21372.54316\n",
      "[1290]\ttrain-rmse:4706.38732\tvalid-rmse:21380.47818\n",
      "[1300]\ttrain-rmse:4670.70896\tvalid-rmse:21364.20714\n",
      "[1310]\ttrain-rmse:4645.23598\tvalid-rmse:21362.71309\n",
      "[1320]\ttrain-rmse:4606.22964\tvalid-rmse:21362.57576\n",
      "[1330]\ttrain-rmse:4572.58576\tvalid-rmse:21362.12090\n",
      "[1340]\ttrain-rmse:4543.63028\tvalid-rmse:21350.65397\n",
      "[1350]\ttrain-rmse:4519.98327\tvalid-rmse:21376.96921\n",
      "[1360]\ttrain-rmse:4491.93988\tvalid-rmse:21382.75285\n",
      "[1370]\ttrain-rmse:4459.28624\tvalid-rmse:21382.30272\n",
      "[1380]\ttrain-rmse:4422.90929\tvalid-rmse:21386.09340\n",
      "[1390]\ttrain-rmse:4394.86795\tvalid-rmse:21398.55866\n",
      "[1400]\ttrain-rmse:4359.41885\tvalid-rmse:21386.17204\n",
      "[1410]\ttrain-rmse:4329.40132\tvalid-rmse:21375.88079\n",
      "[1420]\ttrain-rmse:4299.78062\tvalid-rmse:21370.16544\n",
      "[1430]\ttrain-rmse:4276.80520\tvalid-rmse:21364.68012\n",
      "[1440]\ttrain-rmse:4252.55393\tvalid-rmse:21366.72107\n",
      "[1450]\ttrain-rmse:4219.85925\tvalid-rmse:21359.49190\n",
      "[1460]\ttrain-rmse:4185.80497\tvalid-rmse:21357.64979\n",
      "[1470]\ttrain-rmse:4151.33263\tvalid-rmse:21356.16700\n",
      "[1480]\ttrain-rmse:4116.28052\tvalid-rmse:21353.84018\n",
      "[1490]\ttrain-rmse:4083.88902\tvalid-rmse:21340.04395\n",
      "[1500]\ttrain-rmse:4057.99860\tvalid-rmse:21335.13640\n",
      "[1510]\ttrain-rmse:4028.46092\tvalid-rmse:21329.60510\n",
      "[1520]\ttrain-rmse:3999.24876\tvalid-rmse:21324.86389\n",
      "[1530]\ttrain-rmse:3970.72720\tvalid-rmse:21316.08221\n",
      "[1540]\ttrain-rmse:3946.06025\tvalid-rmse:21314.95317\n",
      "[1550]\ttrain-rmse:3919.00524\tvalid-rmse:21306.39359\n",
      "[1560]\ttrain-rmse:3894.68222\tvalid-rmse:21331.10821\n",
      "[1570]\ttrain-rmse:3865.46765\tvalid-rmse:21355.29879\n",
      "[1580]\ttrain-rmse:3837.04737\tvalid-rmse:21355.53782\n",
      "[1590]\ttrain-rmse:3814.46092\tvalid-rmse:21332.04261\n",
      "[1600]\ttrain-rmse:3795.01680\tvalid-rmse:21349.86102\n",
      "[1610]\ttrain-rmse:3773.64211\tvalid-rmse:21340.91840\n",
      "[1620]\ttrain-rmse:3749.93462\tvalid-rmse:21330.55680\n",
      "[1630]\ttrain-rmse:3721.67759\tvalid-rmse:21338.83782\n",
      "[1640]\ttrain-rmse:3698.20367\tvalid-rmse:21335.90607\n",
      "[1650]\ttrain-rmse:3676.83798\tvalid-rmse:21338.25211\n",
      "[1660]\ttrain-rmse:3658.97791\tvalid-rmse:21320.22794\n",
      "[1670]\ttrain-rmse:3643.65715\tvalid-rmse:21327.35344\n",
      "[1680]\ttrain-rmse:3617.90007\tvalid-rmse:21324.51863\n",
      "[1690]\ttrain-rmse:3599.86531\tvalid-rmse:21322.81540\n",
      "[1700]\ttrain-rmse:3578.07934\tvalid-rmse:21314.50464\n",
      "[1710]\ttrain-rmse:3556.86882\tvalid-rmse:21328.41788\n",
      "[1720]\ttrain-rmse:3531.61318\tvalid-rmse:21341.73630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1730]\ttrain-rmse:3511.10896\tvalid-rmse:21328.30255\n",
      "[1740]\ttrain-rmse:3486.12742\tvalid-rmse:21330.78431\n",
      "[1750]\ttrain-rmse:3466.94563\tvalid-rmse:21345.60339\n",
      "[1760]\ttrain-rmse:3442.24622\tvalid-rmse:21351.62813\n",
      "[1770]\ttrain-rmse:3423.59283\tvalid-rmse:21345.55541\n",
      "[1780]\ttrain-rmse:3400.67721\tvalid-rmse:21344.95492\n",
      "[1790]\ttrain-rmse:3380.54623\tvalid-rmse:21347.84769\n",
      "[1800]\ttrain-rmse:3360.41301\tvalid-rmse:21334.08541\n",
      "[1810]\ttrain-rmse:3338.23958\tvalid-rmse:21347.30748\n",
      "[1820]\ttrain-rmse:3317.42668\tvalid-rmse:21331.37899\n",
      "[1830]\ttrain-rmse:3290.11859\tvalid-rmse:21343.82060\n",
      "[1840]\ttrain-rmse:3270.52087\tvalid-rmse:21341.43758\n",
      "[1849]\ttrain-rmse:3252.71661\tvalid-rmse:21340.57331\n",
      "(14094.901640050552, 0.9262188927320376, array([130762.04, 164400.8 , 190541.88, ..., 176782.62, 123190.79,\n",
      "       222714.34], dtype=float32))\n",
      "MAE from Approach 1 (OE):\n",
      "[20:14:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\ttrain-rmse:172248.92719\tvalid-rmse:180236.17487\n",
      "[10]\ttrain-rmse:67448.79424\tvalid-rmse:72680.75035\n",
      "[20]\ttrain-rmse:34138.94363\tvalid-rmse:38764.54910\n",
      "[30]\ttrain-rmse:24351.80306\tvalid-rmse:29225.71630\n",
      "[40]\ttrain-rmse:21223.01387\tvalid-rmse:26720.83030\n",
      "[50]\ttrain-rmse:19583.05477\tvalid-rmse:25743.35974\n",
      "[60]\ttrain-rmse:18416.76724\tvalid-rmse:25009.37286\n",
      "[70]\ttrain-rmse:17531.79757\tvalid-rmse:24526.66384\n",
      "[80]\ttrain-rmse:16849.73848\tvalid-rmse:24030.46419\n",
      "[90]\ttrain-rmse:16273.53659\tvalid-rmse:23751.50356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisheksinghal/miniforge3/lib/python3.9/site-packages/xgboost/core.py:525: FutureWarning: Pass `evals` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain-rmse:15791.08464\tvalid-rmse:23528.61373\n",
      "[110]\ttrain-rmse:15336.67062\tvalid-rmse:23281.94037\n",
      "[120]\ttrain-rmse:14931.61472\tvalid-rmse:23206.14722\n",
      "[130]\ttrain-rmse:14619.13490\tvalid-rmse:23094.87331\n",
      "[140]\ttrain-rmse:14284.91413\tvalid-rmse:22955.45410\n",
      "[150]\ttrain-rmse:13988.11845\tvalid-rmse:22883.24823\n",
      "[160]\ttrain-rmse:13781.16420\tvalid-rmse:22780.54534\n",
      "[170]\ttrain-rmse:13535.99009\tvalid-rmse:22699.52227\n",
      "[180]\ttrain-rmse:13332.03342\tvalid-rmse:22713.07109\n",
      "[190]\ttrain-rmse:13157.96851\tvalid-rmse:22643.21445\n",
      "[200]\ttrain-rmse:12954.94097\tvalid-rmse:22632.56334\n",
      "[210]\ttrain-rmse:12764.04849\tvalid-rmse:22608.00666\n",
      "[220]\ttrain-rmse:12566.68327\tvalid-rmse:22556.61613\n",
      "[230]\ttrain-rmse:12411.19316\tvalid-rmse:22548.66560\n",
      "[240]\ttrain-rmse:12253.39909\tvalid-rmse:22569.84701\n",
      "[250]\ttrain-rmse:12065.57803\tvalid-rmse:22506.83030\n",
      "[260]\ttrain-rmse:11889.53005\tvalid-rmse:22524.30199\n",
      "[270]\ttrain-rmse:11731.94100\tvalid-rmse:22573.01860\n",
      "[280]\ttrain-rmse:11569.33022\tvalid-rmse:22470.42228\n",
      "[290]\ttrain-rmse:11382.39838\tvalid-rmse:22537.12424\n",
      "[300]\ttrain-rmse:11259.52093\tvalid-rmse:22458.47876\n",
      "[310]\ttrain-rmse:11099.13846\tvalid-rmse:22403.60678\n",
      "[320]\ttrain-rmse:10981.95468\tvalid-rmse:22417.42916\n",
      "[330]\ttrain-rmse:10877.06938\tvalid-rmse:22369.48697\n",
      "[340]\ttrain-rmse:10747.47857\tvalid-rmse:22318.67020\n",
      "[350]\ttrain-rmse:10610.80735\tvalid-rmse:22333.19773\n",
      "[360]\ttrain-rmse:10478.47633\tvalid-rmse:22315.24962\n",
      "[370]\ttrain-rmse:10357.99481\tvalid-rmse:22315.33176\n",
      "[380]\ttrain-rmse:10241.56057\tvalid-rmse:22259.00126\n",
      "[390]\ttrain-rmse:10133.55722\tvalid-rmse:22237.95757\n",
      "[400]\ttrain-rmse:10031.76026\tvalid-rmse:22227.95104\n",
      "[410]\ttrain-rmse:9911.25563\tvalid-rmse:22220.86736\n",
      "[420]\ttrain-rmse:9792.24328\tvalid-rmse:22153.80465\n",
      "[430]\ttrain-rmse:9680.35561\tvalid-rmse:22156.97076\n",
      "[440]\ttrain-rmse:9569.17939\tvalid-rmse:22168.87039\n",
      "[450]\ttrain-rmse:9490.08218\tvalid-rmse:22194.82479\n",
      "[460]\ttrain-rmse:9393.27778\tvalid-rmse:22211.43090\n",
      "[470]\ttrain-rmse:9301.70421\tvalid-rmse:22146.13095\n",
      "[480]\ttrain-rmse:9218.01578\tvalid-rmse:22150.56124\n",
      "[490]\ttrain-rmse:9143.16065\tvalid-rmse:22140.23425\n",
      "[500]\ttrain-rmse:9049.82589\tvalid-rmse:22182.77373\n",
      "[510]\ttrain-rmse:8959.96522\tvalid-rmse:22184.29843\n",
      "[520]\ttrain-rmse:8897.68388\tvalid-rmse:22202.59538\n",
      "[530]\ttrain-rmse:8818.67863\tvalid-rmse:22263.21698\n",
      "[540]\ttrain-rmse:8730.90193\tvalid-rmse:22262.51969\n",
      "[550]\ttrain-rmse:8646.54318\tvalid-rmse:22312.78906\n",
      "[560]\ttrain-rmse:8565.37747\tvalid-rmse:22329.45332\n",
      "[570]\ttrain-rmse:8491.48646\tvalid-rmse:22277.86234\n",
      "[580]\ttrain-rmse:8422.44258\tvalid-rmse:22290.37575\n",
      "[590]\ttrain-rmse:8346.02317\tvalid-rmse:22290.48794\n",
      "[600]\ttrain-rmse:8278.59411\tvalid-rmse:22283.54208\n",
      "[610]\ttrain-rmse:8206.75202\tvalid-rmse:22308.10190\n",
      "[620]\ttrain-rmse:8149.67248\tvalid-rmse:22285.12134\n",
      "[630]\ttrain-rmse:8091.90986\tvalid-rmse:22312.59972\n",
      "[640]\ttrain-rmse:8026.54751\tvalid-rmse:22305.60730\n",
      "[650]\ttrain-rmse:7942.91178\tvalid-rmse:22267.04222\n",
      "[660]\ttrain-rmse:7859.18177\tvalid-rmse:22262.43812\n",
      "[670]\ttrain-rmse:7799.22536\tvalid-rmse:22272.79696\n",
      "[680]\ttrain-rmse:7724.71907\tvalid-rmse:22248.32401\n",
      "[690]\ttrain-rmse:7655.00532\tvalid-rmse:22278.98332\n",
      "[700]\ttrain-rmse:7599.20901\tvalid-rmse:22273.89890\n",
      "[710]\ttrain-rmse:7541.25061\tvalid-rmse:22278.52399\n",
      "[720]\ttrain-rmse:7468.67606\tvalid-rmse:22249.52161\n",
      "[730]\ttrain-rmse:7414.15540\tvalid-rmse:22241.46531\n",
      "[740]\ttrain-rmse:7351.99735\tvalid-rmse:22257.40334\n",
      "[750]\ttrain-rmse:7303.71667\tvalid-rmse:22234.11940\n",
      "[760]\ttrain-rmse:7249.20845\tvalid-rmse:22242.30031\n",
      "[770]\ttrain-rmse:7190.12607\tvalid-rmse:22255.58809\n",
      "[780]\ttrain-rmse:7140.56644\tvalid-rmse:22223.89776\n",
      "[786]\ttrain-rmse:7103.04038\tvalid-rmse:22237.16592\n",
      "(14516.995210535386, 0.9198327920128165, array([138538.06, 176678.7 , 194223.03, ..., 190076.66, 126850.58,\n",
      "       227418.64], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (OE):\") \n",
    "print( xg(oe_X_train, oe_X_valid, y_train, y_valid, oe_x2_test))\n",
    "\n",
    "print(\"MAE from Approach 1 (OE):\") \n",
    "print(xg(OH_X_train, OH_X_valid, y_train, y_valid, OH_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459\n",
      "1459\n",
      "[  1461.           1462.           1463.         ... 166824.75855992\n",
      " 115810.93905396 235515.12760543]\n",
      "        Id      SalePrice\n",
      "0     1461  126753.768159\n",
      "1     1462  162570.546116\n",
      "2     1463  180942.599352\n",
      "3     1464  190389.439780\n",
      "4     1465  184378.625096\n",
      "...    ...            ...\n",
      "1454  2915   81739.063200\n",
      "1455  2916   83960.371853\n",
      "1456  2917  166824.758560\n",
      "1457  2918  115810.939054\n",
      "1458  2919  235515.127605\n",
      "\n",
      "[1459 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "id2= oe_x2_test.Id\n",
    "idcol = id2.to_numpy()\n",
    "print(len(idcol))\n",
    "print(len(oe))\n",
    "import numpy as np\n",
    "print (np.concatenate((idcol,oe),axis=0))\n",
    "sub = pd.DataFrame({'Id':idcol, 'SalePrice':oe})\n",
    "print(sub)\n",
    "sub.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 1 (OE):\") \n",
    "print(rf(oe_X_train, oe_X_valid, y_train, y_valid))\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(rf(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 1 (OE):\") \n",
    "print(cbf(oe_X_train, oe_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(cbf(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 XGBoost\n",
    "\n",
    "def myAutoXG(colsample, lr, md, al, ests):\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = colsample, learning_rate = lr,\n",
    "                max_depth = md, alpha = al, n_estimators = ests)\n",
    "    xg_reg.fit(oe_X_train,y_train)\n",
    "\n",
    "    y_pred = xg_reg.predict(oe_X_valid)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    #print(\"Depth - 500, est : \" + str(ests) + \" lr = \",  lr ,\" RMSE: %f\" % (rmse) + \"R2 Score = \" + str(r2_score(y_valid,y_pred)))\n",
    "    return r2_score(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestScore = 0\n",
    "for colsample in np.arange(0.1, 0.99, 0.1):\n",
    "    for lr in np.arange (0.44,1, 0.1):\n",
    "         for md in range (100,1000, 10):\n",
    "            for al in range (1, 100,10):\n",
    "                for ests in range (100, 500, 10):\n",
    "                        newScore = myAutoXG(colsample, lr, md, al, ests)\n",
    "                        if bestScore + 0.1 < newScore:\n",
    "                            bestScore = newScore\n",
    "                            print (colsample, lr, md, al, ests, newScore)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "eval_metric = [\"error\", \"rmse\"]\n",
    "%time xg_reg.fit(x_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
